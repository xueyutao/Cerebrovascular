# 【GCN实验】
# 正负样本各取一半（各50条死亡病人放在训练和测试集中），精度终于变化了

Epoch: 0001 loss_train: 0.6528 acc_train: 0.6528 loss_val: 0.4059 acc_val: 0.9567 time: 0.0156s
Epoch: 0002 loss_train: 0.6596 acc_train: 0.6528 loss_val: 0.4271 acc_val: 0.9567 time: 0.0156s
Epoch: 0003 loss_train: 0.6502 acc_train: 0.6528 loss_val: 0.4459 acc_val: 0.9567 time: 0.0000s
Epoch: 0004 loss_train: 0.6397 acc_train: 0.6528 loss_val: 0.4597 acc_val: 0.9567 time: 0.0156s
Epoch: 0005 loss_train: 0.6333 acc_train: 0.6528 loss_val: 0.4691 acc_val: 0.9567 time: 0.0156s
Epoch: 0006 loss_train: 0.6342 acc_train: 0.6528 loss_val: 0.4725 acc_val: 0.9567 time: 0.0156s
Epoch: 0007 loss_train: 0.6312 acc_train: 0.6528 loss_val: 0.4726 acc_val: 0.9567 time: 0.0000s
Epoch: 0008 loss_train: 0.6408 acc_train: 0.6528 loss_val: 0.4685 acc_val: 0.9567 time: 0.0156s
Epoch: 0009 loss_train: 0.6308 acc_train: 0.6528 loss_val: 0.4629 acc_val: 0.9567 time: 0.0156s
Epoch: 0010 loss_train: 0.6376 acc_train: 0.6528 loss_val: 0.4559 acc_val: 0.9567 time: 0.0156s
Epoch: 0011 loss_train: 0.6277 acc_train: 0.6528 loss_val: 0.4488 acc_val: 0.9567 time: 0.0000s
Epoch: 0012 loss_train: 0.6198 acc_train: 0.6458 loss_val: 0.4410 acc_val: 0.9567 time: 0.0156s
Epoch: 0013 loss_train: 0.6207 acc_train: 0.6528 loss_val: 0.4343 acc_val: 0.9567 time: 0.0156s
Epoch: 0014 loss_train: 0.6281 acc_train: 0.6528 loss_val: 0.4275 acc_val: 0.9567 time: 0.0000s
Epoch: 0015 loss_train: 0.6138 acc_train: 0.6528 loss_val: 0.4227 acc_val: 0.9567 time: 0.0156s
Epoch: 0016 loss_train: 0.6179 acc_train: 0.6528 loss_val: 0.4174 acc_val: 0.9567 time: 0.0156s
Epoch: 0017 loss_train: 0.6162 acc_train: 0.6458 loss_val: 0.4124 acc_val: 0.9567 time: 0.0156s
Epoch: 0018 loss_train: 0.6152 acc_train: 0.6458 loss_val: 0.4079 acc_val: 0.9567 time: 0.0000s
Epoch: 0019 loss_train: 0.6084 acc_train: 0.6458 loss_val: 0.4038 acc_val: 0.9567 time: 0.0156s
Epoch: 0020 loss_train: 0.6050 acc_train: 0.6458 loss_val: 0.4008 acc_val: 0.9567 time: 0.0156s
Epoch: 0021 loss_train: 0.6019 acc_train: 0.6528 loss_val: 0.3995 acc_val: 0.9567 time: 0.0203s
Epoch: 0022 loss_train: 0.5979 acc_train: 0.6458 loss_val: 0.4003 acc_val: 0.9567 time: 0.0120s
Epoch: 0023 loss_train: 0.5965 acc_train: 0.6389 loss_val: 0.4027 acc_val: 0.9567 time: 0.0130s
Epoch: 0024 loss_train: 0.5949 acc_train: 0.6389 loss_val: 0.4055 acc_val: 0.9567 time: 0.0130s
Epoch: 0025 loss_train: 0.5968 acc_train: 0.6181 loss_val: 0.4073 acc_val: 0.9567 time: 0.0130s
Epoch: 0026 loss_train: 0.6044 acc_train: 0.6111 loss_val: 0.4060 acc_val: 0.9567 time: 0.0130s
Epoch: 0027 loss_train: 0.5867 acc_train: 0.6181 loss_val: 0.4052 acc_val: 0.9500 time: 0.0120s
Epoch: 0028 loss_train: 0.5898 acc_train: 0.6042 loss_val: 0.4026 acc_val: 0.9300 time: 0.0110s
Epoch: 0029 loss_train: 0.5745 acc_train: 0.6181 loss_val: 0.4007 acc_val: 0.9267 time: 0.0120s
Epoch: 0030 loss_train: 0.5621 acc_train: 0.6458 loss_val: 0.3986 acc_val: 0.9233 time: 0.0110s
Epoch: 0031 loss_train: 0.5779 acc_train: 0.5972 loss_val: 0.3968 acc_val: 0.9233 time: 0.0100s
Epoch: 0032 loss_train: 0.5749 acc_train: 0.6111 loss_val: 0.3951 acc_val: 0.9200 time: 0.0100s
Epoch: 0033 loss_train: 0.5698 acc_train: 0.6181 loss_val: 0.3941 acc_val: 0.9167 time: 0.0110s
Epoch: 0034 loss_train: 0.5628 acc_train: 0.6250 loss_val: 0.3913 acc_val: 0.9100 time: 0.0110s
Epoch: 0035 loss_train: 0.5798 acc_train: 0.5972 loss_val: 0.3863 acc_val: 0.9067 time: 0.0120s
Epoch: 0036 loss_train: 0.5708 acc_train: 0.6042 loss_val: 0.3794 acc_val: 0.9067 time: 0.0110s
Epoch: 0037 loss_train: 0.5655 acc_train: 0.5972 loss_val: 0.3724 acc_val: 0.9067 time: 0.0120s
Epoch: 0038 loss_train: 0.5574 acc_train: 0.6042 loss_val: 0.3673 acc_val: 0.9067 time: 0.0130s
Epoch: 0039 loss_train: 0.5514 acc_train: 0.6181 loss_val: 0.3648 acc_val: 0.9033 time: 0.0130s
Epoch: 0040 loss_train: 0.5569 acc_train: 0.5833 loss_val: 0.3606 acc_val: 0.9033 time: 0.0130s
Epoch: 0041 loss_train: 0.5489 acc_train: 0.5903 loss_val: 0.3546 acc_val: 0.9067 time: 0.0130s
Epoch: 0042 loss_train: 0.5421 acc_train: 0.5972 loss_val: 0.3499 acc_val: 0.9067 time: 0.0120s
Epoch: 0043 loss_train: 0.5304 acc_train: 0.6042 loss_val: 0.3489 acc_val: 0.8967 time: 0.0130s
Epoch: 0044 loss_train: 0.5441 acc_train: 0.5903 loss_val: 0.3489 acc_val: 0.8967 time: 0.0130s
Epoch: 0045 loss_train: 0.5397 acc_train: 0.5972 loss_val: 0.3482 acc_val: 0.8933 time: 0.0120s
Epoch: 0046 loss_train: 0.5304 acc_train: 0.6042 loss_val: 0.3493 acc_val: 0.8867 time: 0.0130s
Epoch: 0047 loss_train: 0.5251 acc_train: 0.6042 loss_val: 0.3491 acc_val: 0.8867 time: 0.0120s
Epoch: 0048 loss_train: 0.5316 acc_train: 0.5833 loss_val: 0.3459 acc_val: 0.8867 time: 0.0110s
Epoch: 0049 loss_train: 0.5135 acc_train: 0.5694 loss_val: 0.3444 acc_val: 0.8867 time: 0.0120s
Epoch: 0050 loss_train: 0.5252 acc_train: 0.5972 loss_val: 0.3405 acc_val: 0.8867 time: 0.0120s
Epoch: 0051 loss_train: 0.5099 acc_train: 0.6042 loss_val: 0.3343 acc_val: 0.8867 time: 0.0120s
Epoch: 0052 loss_train: 0.5209 acc_train: 0.5764 loss_val: 0.3262 acc_val: 0.8867 time: 0.0110s
Epoch: 0053 loss_train: 0.4928 acc_train: 0.6042 loss_val: 0.3215 acc_val: 0.8867 time: 0.0110s
Epoch: 0054 loss_train: 0.5233 acc_train: 0.5694 loss_val: 0.3185 acc_val: 0.8867 time: 0.0110s
Epoch: 0055 loss_train: 0.4990 acc_train: 0.6042 loss_val: 0.3150 acc_val: 0.8867 time: 0.0030s
Epoch: 0056 loss_train: 0.5102 acc_train: 0.5903 loss_val: 0.3099 acc_val: 0.8900 time: 0.0156s
Epoch: 0057 loss_train: 0.4691 acc_train: 0.6181 loss_val: 0.3084 acc_val: 0.8900 time: 0.0173s
Epoch: 0058 loss_train: 0.4831 acc_train: 0.6111 loss_val: 0.3088 acc_val: 0.8867 time: 0.0000s
Epoch: 0059 loss_train: 0.4926 acc_train: 0.5694 loss_val: 0.3083 acc_val: 0.8833 time: 0.0156s
Epoch: 0060 loss_train: 0.4941 acc_train: 0.5972 loss_val: 0.3054 acc_val: 0.8833 time: 0.0156s
Epoch: 0061 loss_train: 0.4836 acc_train: 0.5625 loss_val: 0.3003 acc_val: 0.8833 time: 0.0156s
Epoch: 0062 loss_train: 0.4939 acc_train: 0.5486 loss_val: 0.2922 acc_val: 0.8900 time: 0.0156s
Epoch: 0063 loss_train: 0.4652 acc_train: 0.5972 loss_val: 0.2856 acc_val: 0.8967 time: 0.0000s
Epoch: 0064 loss_train: 0.4643 acc_train: 0.5833 loss_val: 0.2829 acc_val: 0.8967 time: 0.0156s
Epoch: 0065 loss_train: 0.4724 acc_train: 0.6111 loss_val: 0.2825 acc_val: 0.8900 time: 0.0156s
Epoch: 0066 loss_train: 0.4711 acc_train: 0.5625 loss_val: 0.2819 acc_val: 0.8867 time: 0.0156s
Epoch: 0067 loss_train: 0.4591 acc_train: 0.5972 loss_val: 0.2821 acc_val: 0.8867 time: 0.0000s
Epoch: 0068 loss_train: 0.4708 acc_train: 0.6042 loss_val: 0.2808 acc_val: 0.8833 time: 0.0156s
Epoch: 0069 loss_train: 0.4594 acc_train: 0.9444 loss_val: 0.2779 acc_val: 0.8800 time: 0.0156s
Epoch: 0070 loss_train: 0.4377 acc_train: 0.9514 loss_val: 0.2754 acc_val: 0.9233 time: 0.0156s
Epoch: 0071 loss_train: 0.4433 acc_train: 0.9444 loss_val: 0.2738 acc_val: 0.9167 time: 0.0000s
Epoch: 0072 loss_train: 0.4555 acc_train: 0.9444 loss_val: 0.2739 acc_val: 0.9100 time: 0.0156s
Epoch: 0073 loss_train: 0.4392 acc_train: 0.9583 loss_val: 0.2781 acc_val: 0.8967 time: 0.0156s
Epoch: 0074 loss_train: 0.4393 acc_train: 0.9306 loss_val: 0.2824 acc_val: 0.8900 time: 0.0156s
Epoch: 0075 loss_train: 0.4494 acc_train: 0.9167 loss_val: 0.2850 acc_val: 0.8900 time: 0.0156s
Epoch: 0076 loss_train: 0.4200 acc_train: 0.9583 loss_val: 0.2869 acc_val: 0.8867 time: 0.0000s
Epoch: 0077 loss_train: 0.4690 acc_train: 0.8819 loss_val: 0.2822 acc_val: 0.8867 time: 0.0171s
Epoch: 0078 loss_train: 0.4320 acc_train: 0.8958 loss_val: 0.2768 acc_val: 0.8867 time: 0.0156s
Epoch: 0079 loss_train: 0.4311 acc_train: 0.9444 loss_val: 0.2696 acc_val: 0.8967 time: 0.0156s
Epoch: 0080 loss_train: 0.4227 acc_train: 0.9306 loss_val: 0.2599 acc_val: 0.9267 time: 0.0000s
Epoch: 0081 loss_train: 0.4111 acc_train: 0.9444 loss_val: 0.2512 acc_val: 0.9567 time: 0.0156s
Epoch: 0082 loss_train: 0.4253 acc_train: 0.9583 loss_val: 0.2470 acc_val: 0.9633 time: 0.0156s
Epoch: 0083 loss_train: 0.4105 acc_train: 0.9444 loss_val: 0.2453 acc_val: 0.9667 time: 0.0156s
Epoch: 0084 loss_train: 0.4089 acc_train: 0.9514 loss_val: 0.2449 acc_val: 0.9633 time: 0.0156s
Epoch: 0085 loss_train: 0.3905 acc_train: 0.9653 loss_val: 0.2457 acc_val: 0.9533 time: 0.0000s
Epoch: 0086 loss_train: 0.3871 acc_train: 0.9583 loss_val: 0.2481 acc_val: 0.9467 time: 0.0156s
Epoch: 0087 loss_train: 0.4080 acc_train: 0.9514 loss_val: 0.2492 acc_val: 0.9500 time: 0.0156s
Epoch: 0088 loss_train: 0.4018 acc_train: 0.9236 loss_val: 0.2489 acc_val: 0.9500 time: 0.0156s
Epoch: 0089 loss_train: 0.4143 acc_train: 0.9236 loss_val: 0.2477 acc_val: 0.9500 time: 0.0156s
Epoch: 0090 loss_train: 0.4116 acc_train: 0.9306 loss_val: 0.2472 acc_val: 0.9500 time: 0.0000s
Epoch: 0091 loss_train: 0.4083 acc_train: 0.9306 loss_val: 0.2445 acc_val: 0.9500 time: 0.0156s
Epoch: 0092 loss_train: 0.3698 acc_train: 0.9514 loss_val: 0.2429 acc_val: 0.9500 time: 0.0156s
Epoch: 0093 loss_train: 0.4046 acc_train: 0.9375 loss_val: 0.2392 acc_val: 0.9533 time: 0.0156s
Epoch: 0094 loss_train: 0.3889 acc_train: 0.9167 loss_val: 0.2335 acc_val: 0.9533 time: 0.0156s
Epoch: 0095 loss_train: 0.3875 acc_train: 0.9375 loss_val: 0.2271 acc_val: 0.9567 time: 0.0156s
Epoch: 0096 loss_train: 0.3894 acc_train: 0.9236 loss_val: 0.2200 acc_val: 0.9700 time: 0.0156s
Epoch: 0097 loss_train: 0.3869 acc_train: 0.9514 loss_val: 0.2148 acc_val: 0.9733 time: 0.0156s
Epoch: 0098 loss_train: 0.3693 acc_train: 0.9375 loss_val: 0.2113 acc_val: 0.9733 time: 0.0156s
Epoch: 0099 loss_train: 0.3667 acc_train: 0.9514 loss_val: 0.2109 acc_val: 0.9733 time: 0.0156s
Epoch: 0100 loss_train: 0.3810 acc_train: 0.9375 loss_val: 0.2122 acc_val: 0.9700 time: 0.0156s
Optimization Finished!
Total time elapsed: 1.2368s
Test set results: loss= 0.3554 accuracy= 0.9758
