# 【GCN实验】
# 吸烟的病人相连，不吸烟的病人相连。预测是否吸烟，以及位置，精度61%

Epoch: 0001 loss_train: 88.2328 acc_train: 0.5500 loss_val: 52.6019 acc_val: 0.5933 time: 3.4419s
Epoch: 0002 loss_train: 52.0750 acc_train: 0.5500 loss_val: 7.1686 acc_val: 0.5933 time: 2.5569s
Epoch: 0003 loss_train: 12.8881 acc_train: 0.5500 loss_val: 15.3079 acc_val: 0.3767 time: 2.5463s
Epoch: 0004 loss_train: 24.7062 acc_train: 0.3071 loss_val: 17.9370 acc_val: 0.3767 time: 2.5835s
Epoch: 0005 loss_train: 22.7530 acc_train: 0.3286 loss_val: 12.2533 acc_val: 0.3800 time: 2.5868s
Epoch: 0006 loss_train: 11.8754 acc_train: 0.3357 loss_val: 5.5931 acc_val: 0.3800 time: 2.6067s
Epoch: 0007 loss_train: 6.6802 acc_train: 0.3357 loss_val: 1.5792 acc_val: 0.9767 time: 2.5484s
Epoch: 0008 loss_train: 3.9986 acc_train: 0.8786 loss_val: 1.2872 acc_val: 0.9800 time: 2.5466s
Epoch: 0009 loss_train: 4.9940 acc_train: 0.8571 loss_val: 1.8965 acc_val: 0.6033 time: 2.5634s
Epoch: 0010 loss_train: 4.6798 acc_train: 0.5429 loss_val: 2.7028 acc_val: 0.6033 time: 2.5564s
Epoch: 0011 loss_train: 3.8812 acc_train: 0.5643 loss_val: 2.2114 acc_val: 0.6033 time: 2.5603s
Epoch: 0012 loss_train: 3.5219 acc_train: 0.5643 loss_val: 1.6557 acc_val: 0.6033 time: 2.5561s
Epoch: 0013 loss_train: 2.5260 acc_train: 0.5786 loss_val: 1.4867 acc_val: 0.6033 time: 2.6050s
Epoch: 0014 loss_train: 2.6652 acc_train: 0.5786 loss_val: 1.4289 acc_val: 0.6067 time: 2.6440s
Epoch: 0015 loss_train: 1.8638 acc_train: 0.5714 loss_val: 3.9032 acc_val: 0.6067 time: 2.6250s
Epoch: 0016 loss_train: 3.3316 acc_train: 0.5714 loss_val: 1.6780 acc_val: 0.6067 time: 2.5871s
Epoch: 0017 loss_train: 2.1894 acc_train: 0.5643 loss_val: 1.1462 acc_val: 0.6067 time: 2.5897s
Epoch: 0018 loss_train: 2.2982 acc_train: 0.5643 loss_val: 1.1044 acc_val: 0.6100 time: 2.5762s
Epoch: 0019 loss_train: 2.2947 acc_train: 0.5786 loss_val: 1.0903 acc_val: 0.6100 time: 2.5653s
Epoch: 0020 loss_train: 2.1325 acc_train: 0.5786 loss_val: 1.0843 acc_val: 0.6133 time: 2.5382s
Epoch: 0021 loss_train: 1.1531 acc_train: 0.5643 loss_val: 1.0803 acc_val: 0.6133 time: 2.5475s
Epoch: 0022 loss_train: 1.9940 acc_train: 0.5786 loss_val: 1.0764 acc_val: 0.6133 time: 2.5548s
Epoch: 0023 loss_train: 1.0466 acc_train: 0.5714 loss_val: 1.0724 acc_val: 0.6133 time: 2.6153s
Epoch: 0024 loss_train: 1.0777 acc_train: 0.5714 loss_val: 1.0685 acc_val: 0.6133 time: 2.5968s
Epoch: 0025 loss_train: 1.0425 acc_train: 0.5714 loss_val: 1.0645 acc_val: 0.6133 time: 2.5992s
Epoch: 0026 loss_train: 1.0526 acc_train: 0.5786 loss_val: 1.3524 acc_val: 0.6133 time: 2.6921s
Epoch: 0027 loss_train: 1.2710 acc_train: 0.5786 loss_val: 1.4068 acc_val: 0.6133 time: 2.6307s
Epoch: 0028 loss_train: 1.3054 acc_train: 0.5714 loss_val: 1.0975 acc_val: 0.6133 time: 2.6558s
Epoch: 0029 loss_train: 1.0500 acc_train: 0.5786 loss_val: 1.1769 acc_val: 0.6133 time: 2.6343s
Epoch: 0030 loss_train: 1.1335 acc_train: 0.5714 loss_val: 1.0449 acc_val: 0.6133 time: 2.5932s
Epoch: 0031 loss_train: 1.0202 acc_train: 0.5786 loss_val: 1.0408 acc_val: 0.6133 time: 2.6227s
Epoch: 0032 loss_train: 1.6597 acc_train: 0.5571 loss_val: 1.0367 acc_val: 0.6133 time: 2.5373s
Epoch: 0033 loss_train: 1.0309 acc_train: 0.5643 loss_val: 1.0326 acc_val: 0.6133 time: 2.5359s
Epoch: 0034 loss_train: 1.5474 acc_train: 0.5643 loss_val: 1.0285 acc_val: 0.6133 time: 2.5671s
Epoch: 0035 loss_train: 1.0013 acc_train: 0.5857 loss_val: 1.0245 acc_val: 0.6133 time: 2.8331s
Epoch: 0036 loss_train: 1.4271 acc_train: 0.5714 loss_val: 1.0205 acc_val: 0.6133 time: 2.6104s
Epoch: 0037 loss_train: 1.0282 acc_train: 0.5786 loss_val: 1.0204 acc_val: 0.6100 time: 2.5556s
Epoch: 0038 loss_train: 1.0200 acc_train: 0.5714 loss_val: 1.0165 acc_val: 0.6100 time: 2.5778s
Epoch: 0039 loss_train: 1.3000 acc_train: 0.5643 loss_val: 1.0126 acc_val: 0.6100 time: 2.5782s
Epoch: 0040 loss_train: 0.9886 acc_train: 0.5857 loss_val: 1.0088 acc_val: 0.6100 time: 2.5939s
Epoch: 0041 loss_train: 1.1751 acc_train: 0.5571 loss_val: 1.0050 acc_val: 0.6100 time: 2.5617s
Epoch: 0042 loss_train: 1.4135 acc_train: 0.5714 loss_val: 1.0013 acc_val: 0.6100 time: 2.5542s
Epoch: 0043 loss_train: 1.0027 acc_train: 0.5643 loss_val: 0.9977 acc_val: 0.6100 time: 2.6211s
Epoch: 0044 loss_train: 0.9791 acc_train: 0.5857 loss_val: 0.9941 acc_val: 0.6100 time: 2.6300s
Epoch: 0045 loss_train: 0.9768 acc_train: 0.5857 loss_val: 0.9905 acc_val: 0.6100 time: 2.5684s
Epoch: 0046 loss_train: 0.9766 acc_train: 0.5857 loss_val: 0.9870 acc_val: 0.6100 time: 2.5547s
Epoch: 0047 loss_train: 1.3566 acc_train: 0.5643 loss_val: 0.9835 acc_val: 0.6100 time: 2.5468s
Epoch: 0048 loss_train: 0.9756 acc_train: 0.5857 loss_val: 1.2942 acc_val: 0.6133 time: 2.6048s
Epoch: 0049 loss_train: 1.2023 acc_train: 0.6143 loss_val: 0.9766 acc_val: 0.6100 time: 2.6240s
Epoch: 0050 loss_train: 0.9888 acc_train: 0.5714 loss_val: 0.9732 acc_val: 0.6100 time: 2.6358s
Epoch: 0051 loss_train: 0.9775 acc_train: 0.5786 loss_val: 0.9698 acc_val: 0.6100 time: 2.7148s
Epoch: 0052 loss_train: 0.9713 acc_train: 0.5786 loss_val: 0.9666 acc_val: 0.6100 time: 2.7076s
Epoch: 0053 loss_train: 0.9599 acc_train: 0.5857 loss_val: 0.9633 acc_val: 0.6100 time: 2.6003s
Epoch: 0054 loss_train: 0.9584 acc_train: 0.5857 loss_val: 0.9602 acc_val: 0.6100 time: 2.6038s
Epoch: 0055 loss_train: 0.9654 acc_train: 0.5786 loss_val: 0.9571 acc_val: 0.6100 time: 2.5997s
Epoch: 0056 loss_train: 1.2553 acc_train: 0.5714 loss_val: 0.9541 acc_val: 0.6100 time: 2.5833s
Epoch: 0057 loss_train: 0.9624 acc_train: 0.5786 loss_val: 0.9511 acc_val: 0.6100 time: 2.5836s
Epoch: 0058 loss_train: 1.2308 acc_train: 0.5786 loss_val: 0.9484 acc_val: 0.6100 time: 2.6119s
Epoch: 0059 loss_train: 0.9693 acc_train: 0.5714 loss_val: 0.9460 acc_val: 0.6100 time: 2.6200s
Epoch: 0060 loss_train: 0.9576 acc_train: 0.5786 loss_val: 0.9446 acc_val: 0.6100 time: 2.5990s
Epoch: 0061 loss_train: 0.9747 acc_train: 0.5643 loss_val: 0.9447 acc_val: 0.6067 time: 2.5900s
Epoch: 0062 loss_train: 1.2197 acc_train: 0.5643 loss_val: 0.9421 acc_val: 0.6067 time: 2.5970s
Epoch: 0063 loss_train: 0.9634 acc_train: 0.5714 loss_val: 0.9396 acc_val: 0.6067 time: 2.6010s
Epoch: 0064 loss_train: 0.9494 acc_train: 0.5786 loss_val: 0.9371 acc_val: 0.6067 time: 2.5982s
Epoch: 0065 loss_train: 0.9578 acc_train: 0.5714 loss_val: 0.9347 acc_val: 0.6067 time: 2.5996s
Epoch: 0066 loss_train: 0.9700 acc_train: 0.5643 loss_val: 0.9324 acc_val: 0.6067 time: 2.5884s
Epoch: 0067 loss_train: 0.9379 acc_train: 0.5857 loss_val: 0.9300 acc_val: 0.6067 time: 2.5827s
Epoch: 0068 loss_train: 1.1647 acc_train: 0.5786 loss_val: 0.9278 acc_val: 0.6067 time: 2.6003s
Epoch: 0069 loss_train: 0.9483 acc_train: 0.5714 loss_val: 0.9255 acc_val: 0.6067 time: 2.5940s
Epoch: 0070 loss_train: 0.9445 acc_train: 0.5786 loss_val: 0.9234 acc_val: 0.6067 time: 2.6333s
Epoch: 0071 loss_train: 0.9434 acc_train: 0.5786 loss_val: 0.9212 acc_val: 0.6067 time: 2.6486s
Epoch: 0072 loss_train: 0.9543 acc_train: 0.5643 loss_val: 0.9192 acc_val: 0.6067 time: 2.5782s
Epoch: 0073 loss_train: 0.9631 acc_train: 0.5643 loss_val: 0.9171 acc_val: 0.6067 time: 2.6639s
Epoch: 0074 loss_train: 0.9453 acc_train: 0.5786 loss_val: 0.9151 acc_val: 0.6067 time: 2.6396s
Epoch: 0075 loss_train: 0.9395 acc_train: 0.5786 loss_val: 0.9132 acc_val: 0.6067 time: 2.6223s
Epoch: 0076 loss_train: 0.9494 acc_train: 0.5714 loss_val: 0.9113 acc_val: 0.6067 time: 2.6087s
Epoch: 0077 loss_train: 1.1451 acc_train: 0.5643 loss_val: 0.9094 acc_val: 0.6067 time: 2.6190s
Epoch: 0078 loss_train: 0.9403 acc_train: 0.5786 loss_val: 0.9076 acc_val: 0.6067 time: 2.6153s
Epoch: 0079 loss_train: 1.1323 acc_train: 0.5643 loss_val: 0.9059 acc_val: 0.6067 time: 2.5833s
Epoch: 0080 loss_train: 0.9461 acc_train: 0.5714 loss_val: 0.9041 acc_val: 0.6067 time: 2.5834s
Epoch: 0081 loss_train: 0.9620 acc_train: 0.5571 loss_val: 0.9025 acc_val: 0.6067 time: 2.6045s
Epoch: 0082 loss_train: 0.9447 acc_train: 0.5714 loss_val: 0.9008 acc_val: 0.6067 time: 2.6470s
Epoch: 0083 loss_train: 0.9327 acc_train: 0.5786 loss_val: 0.8992 acc_val: 0.6067 time: 2.6700s
Epoch: 0084 loss_train: 0.9344 acc_train: 0.5786 loss_val: 0.8976 acc_val: 0.6067 time: 2.6500s
Epoch: 0085 loss_train: 1.0999 acc_train: 0.5714 loss_val: 0.8961 acc_val: 0.6067 time: 2.6680s
Epoch: 0086 loss_train: 0.9349 acc_train: 0.5786 loss_val: 0.8945 acc_val: 0.6067 time: 2.6493s
Epoch: 0087 loss_train: 1.0972 acc_train: 0.5714 loss_val: 0.8931 acc_val: 0.6067 time: 2.6308s
Epoch: 0088 loss_train: 0.9335 acc_train: 0.5786 loss_val: 0.8916 acc_val: 0.6067 time: 2.6591s
Epoch: 0089 loss_train: 0.9287 acc_train: 0.5786 loss_val: 0.8902 acc_val: 0.6067 time: 2.6203s
Epoch: 0090 loss_train: 0.9281 acc_train: 0.5786 loss_val: 0.8887 acc_val: 0.6067 time: 2.6137s
Epoch: 0091 loss_train: 0.9392 acc_train: 0.5714 loss_val: 0.8873 acc_val: 0.6067 time: 2.5985s
Epoch: 0092 loss_train: 0.9203 acc_train: 0.5857 loss_val: 0.8860 acc_val: 0.6067 time: 2.5839s
Epoch: 0093 loss_train: 0.9263 acc_train: 0.5786 loss_val: 0.8846 acc_val: 0.6067 time: 2.7768s
Epoch: 0094 loss_train: 0.9389 acc_train: 0.5714 loss_val: 0.8833 acc_val: 0.6067 time: 2.6843s
Epoch: 0095 loss_train: 0.9252 acc_train: 0.5786 loss_val: 0.8820 acc_val: 0.6067 time: 2.6621s
Epoch: 0096 loss_train: 0.9248 acc_train: 0.5786 loss_val: 0.8807 acc_val: 0.6067 time: 2.6586s
Epoch: 0097 loss_train: 0.9361 acc_train: 0.5714 loss_val: 0.8794 acc_val: 0.6067 time: 2.6326s
Epoch: 0098 loss_train: 1.0607 acc_train: 0.5643 loss_val: 0.8782 acc_val: 0.6067 time: 2.6119s
Epoch: 0099 loss_train: 0.9256 acc_train: 0.5786 loss_val: 0.8770 acc_val: 0.6067 time: 2.6126s
Epoch: 0100 loss_train: 0.9349 acc_train: 0.5714 loss_val: 0.8759 acc_val: 0.6067 time: 2.6091s
Optimization Finished!
Total time elapsed: 261.6372s
Test set results: loss= 0.8864 accuracy= 0.6160
